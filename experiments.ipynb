{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf490910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4e4f3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import tensorflow as tf\n",
    "##tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9b32134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the dataset\n",
    "data= pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15b6de3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France  Female  ...               1        101348.88       1\n",
       "1             608     Spain  Female  ...               1        112542.58       0\n",
       "2             502    France  Female  ...               0        113931.57       1\n",
       "3             699    France  Female  ...               0         93826.63       0\n",
       "4             850     Spain  Female  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France    Male  ...               0         96270.64       0\n",
       "9996          516    France    Male  ...               1        101699.77       0\n",
       "9997          709    France  Female  ...               1         42085.58       1\n",
       "9998          772   Germany    Male  ...               0         92888.52       1\n",
       "9999          792    France  Female  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preprocess the data\n",
    "### Drop irrelevent columns\n",
    "data= data.drop(['RowNumber','CustomerId','Surname'], axis=1)     ## Axis=1 means column wise.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a856a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France       0  ...               1        101348.88       1\n",
       "1             608     Spain       0  ...               1        112542.58       0\n",
       "2             502    France       0  ...               0        113931.57       1\n",
       "3             699    France       0  ...               0         93826.63       0\n",
       "4             850     Spain       0  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France       1  ...               0         96270.64       0\n",
       "9996          516    France       1  ...               1        101699.77       0\n",
       "9997          709    France       0  ...               1         42085.58       1\n",
       "9998          772   Germany       1  ...               0         92888.52       1\n",
       "9999          792    France       0  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encode categorical variables (this is one of the encoding technique)\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender']= label_encoder_gender.fit_transform(data['Gender'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dafdebf",
   "metadata": {},
   "source": [
    "For geography column we have 3 categories: Here if we go ahead and apply labelEncoder() then france=0, Spain=1, Germany=2,and when this types of numbers are specifically coming up, then there is a problem because, when we assign a value of germany to 2, At the end of the day ANN is all about numerical and calculations, since the number/label of germany is 2, it will just consider that Germany is grater than spain, or spain is greater than france, and this should not happen, so for this particular case, we will not use label encoder instead we will use OneHotEncoding. OneHotEncoding will give value with respect to 0s and 1s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2c92f271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 10000 stored elements and shape (10000, 3)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OneHotEncoder 'Geography'\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder_geo=OneHotEncoder()\n",
    "geo_encoder=onehot_encoder_geo.fit_transform(data[['Geography']])\n",
    "geo_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ea903bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_encoder.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ba0f9286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder_geo.get_feature_names_out(['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c0e628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_encoded_df=pd.DataFrame(geo_encoder.toarray(),columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "geo_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "90dff656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0          619       0  ...                0.0              0.0\n",
       "1          608       0  ...                0.0              1.0\n",
       "2          502       0  ...                0.0              0.0\n",
       "3          699       0  ...                0.0              0.0\n",
       "4          850       0  ...                0.0              1.0\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Combine one hot encoder columns with the original data\n",
    "data=pd.concat([data.drop('Geography',axis=1),geo_encoded_df],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36574055",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7072d1c9",
   "metadata": {},
   "source": [
    "What is pickle?\n",
    "pickle is a built-in Python module used to save Python objects to a file.\n",
    "Think of it like \"saving your work\", but for Python variables, models, encoders, etc.\n",
    "You can also use it to load that work back later, just like saving and opening a game.\n",
    "\n",
    "_____________________________________________________________________________________________________________\n",
    "What does dump mean?\n",
    "pickle.dump(object, file) means:\n",
    "👉 \"Put this object into that file using pickle format.\"Think of dump like \"dumping the contents of a backpack into a locker\" — saving something to use later.\n",
    "\n",
    "_____________________________________________________________________________________________________________\n",
    "What does 'wb' mean?\n",
    "'wb' stands for:\n",
    "w → \"write\" (you want to write to the file)\n",
    "b → \"binary\" (pickle needs binary format, not text). So 'wb' = write in binary mode.\n",
    "\n",
    "_____________________________________________________________________________________________________________\n",
    "What's happening?\n",
    "label_encoder_gender and onehot_encoder_geo are probably sklearn encoders used in a machine learning project.\n",
    "You’re saving them so you can use the exact same encoders later when you:\n",
    "\n",
    "*Load a model\n",
    "\n",
    "*Predict new data\n",
    "\n",
    "*Keep consistent data preprocessing\n",
    "\n",
    "_____________________________________________________________________________________________________________\n",
    "Word:\n",
    "\n",
    "pickle - Module to save/load Python objects\n",
    "\n",
    "dump() - Save the object to a file\n",
    "\n",
    "'wb' - Write in binary mode (for saving)\n",
    "\n",
    "'rb' - Read in binary mode (for loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56e8b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the encoders and scaler.   \n",
    "with open('label_encoder_gender.pkl','wb') as file:\n",
    "    pickle.dump(label_encoder_gender,file) \n",
    "  \n",
    "\n",
    "with open('onehot_encoder_geo.pkl','wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "26ef7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataset into independent and dependent \n",
    "X=data.drop('Exited', axis=1)           ## Input features (independent variables)\n",
    "y= data['Exited']                       ## Output/label (dependent variable)\n",
    "\n",
    "## Split the data in training and testing sets\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "## Scale these features\n",
    "scaler=StandardScaler()              ## Create a scaler object\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb8171",
   "metadata": {},
   "source": [
    "What is \"scale\"?\n",
    "To scale data means to change the values in your dataset so they are all within a similar range — without changing their relationships.\n",
    "\n",
    "In simple words:\n",
    "\n",
    "Scaling” means adjusting all the numbers in your dataset so they’re in the same range — like normalizing students' grades out of 10 even if one teacher used 100 marks and another used 50.\n",
    "\n",
    "\n",
    "🎯 Why scale?\n",
    "\n",
    "Imagine this data:\n",
    "Feature with values:\n",
    "\n",
    "Age (in years)\t25, 30, 45\n",
    "\n",
    "Salary (in ₹ rupees)\t20,000, 50,000, 90,000\n",
    "\n",
    "Now think about this:\n",
    "These values are very different in scale.\n",
    "If you give this to a machine learning model, it might think salary is \"more important\" just because the numbers are bigger — even if it’s not!\n",
    "So we scale the data to bring all the features to a similar range, like -1 to +1 or 0 to 1.\n",
    "\n",
    "_________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    " Standard Scaling\n",
    "You're using:\n",
    "\n",
    "scaler = StandardScaler() - This does Standard Scaling, also called Z-score normalization. It converts each feature so that:\n",
    "\n",
    "*The mean (average) becomes 0\n",
    "\n",
    "*The standard deviation becomes 1\n",
    "\n",
    "Formula:\n",
    "\n",
    "scaled value = value − mean/standard deviation\n",
    "\n",
    "​_______________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler():This creates a StandardScaler object from sklearn.preprocessing.\n",
    "\n",
    "______________________________________________________________________________________________________________\n",
    "Term:\n",
    "\n",
    "scaler - A variable name for a scaling tool\n",
    "\n",
    "StandardScaler() - A scikit-learn scaler that standardizes features\n",
    "\n",
    "fit() - Learns the mean and std from data\n",
    "\n",
    "transform() - Applies the learned scaling\n",
    "\n",
    "fit_transform() - Shortcut to do both at once on training data\n",
    "\n",
    "______________________________________________________________________________________________________________\n",
    "What is scaler.fit_transform()?\n",
    "This method does two things in one step:\n",
    "fit() → calculates the mean and standard deviation of the training data.\n",
    "transform() → uses those numbers to scale the data.\n",
    "\n",
    "______________________________________________________________________________________________________________\n",
    "fit_transform() does two jobs:\n",
    "fit() — Looks at all the numbers in X_train, and calculates:\n",
    "        *The mean (average) of each column\n",
    "        *The standard deviation of each column.\n",
    "\n",
    "transform() — Then uses that info to scale all the values like this.\n",
    " new_value = (value - mean) / standard_deviation\n",
    "\n",
    "______________________________________________________________________________________________________________\n",
    "X_test = scaler.transform(X_test):\n",
    "Very important step.You do NOT fit again on test data.You just use the same mean and std learned from X_train to scale X_test.This keeps your model honest — you’re not “peeking” at the test set during training.\n",
    "\n",
    "______________________________________________________________________________________________________________\n",
    "Why Scaling is Important?\n",
    "Some ML models (especially neural networks and gradient-based models) work much better and faster when all input features are scaled evenly.\n",
    "Imagine you're comparing someone's weight (in kg) to their income (in ₹ rupees). One number is in hundreds, the other in lakhs — the model will get confused unless you scale them down to a similar range.\n",
    "\n",
    "\n",
    "________________________________________________________________________________________________________________\n",
    "Line of Code:\n",
    "\n",
    "scaler = StandardScaler() - Create the scaler tool\n",
    "\n",
    "fit_transform(X_train) - Learn scaling from training data + apply it\n",
    "\n",
    "transform(X_test) - Apply the same scaling to test data (without re-learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "738701c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35649971,  0.91324755, -0.6557859 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [-0.20389777,  0.91324755,  0.29493847, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802],\n",
       "       [-0.96147213,  0.91324755, -1.41636539, ..., -0.99850112,\n",
       "        -0.57946723,  1.73494238],\n",
       "       ...,\n",
       "       [ 0.86500853, -1.09499335, -0.08535128, ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.15932282,  0.91324755,  0.3900109 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.47065475,  0.91324755,  1.15059039, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cd75893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl','wb') as file:\n",
    "      pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e386af20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0             619       0  ...                0.0              0.0\n",
       "1             608       0  ...                0.0              1.0\n",
       "2             502       0  ...                0.0              0.0\n",
       "3             699       0  ...                0.0              0.0\n",
       "4             850       0  ...                0.0              1.0\n",
       "...           ...     ...  ...                ...              ...\n",
       "9995          771       1  ...                0.0              0.0\n",
       "9996          516       1  ...                0.0              0.0\n",
       "9997          709       0  ...                0.0              0.0\n",
       "9998          772       1  ...                1.0              0.0\n",
       "9999          792       0  ...                0.0              0.0\n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc77db",
   "metadata": {},
   "source": [
    "ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7dde6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7df637",
   "metadata": {},
   "source": [
    "🧠 What is Dense in Keras?\n",
    "In Keras (which is a tool to build neural networks), a Dense layer is the most basic and common type of layer.\n",
    "\n",
    "💡 Simple Definition:\n",
    "A Dense layer is a layer where every neuron is connected to every neuron in the previous layer.\n",
    "That’s why it’s also called a fully connected layer.\n",
    "\n",
    "✅ When do we use Dense?\n",
    "1. In most deep learning models — especially in classification, regression, or the final output layer.\n",
    "\n",
    "2. After extracting features (like from CNNs or LSTMs), you often pass them into Dense layers.\n",
    "______________________________________________________________________________________________________________________\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard ->This line is importing tools from Keras, part of the TensorFlow library.\n",
    "\n",
    "You are bringing in:\n",
    "1. EarlyStopping\n",
    "2. TensorBoard\n",
    "These are both callbacks. Let’s explain everything word by word 👇\n",
    "\n",
    "🧠 What are \"callbacks\" in Keras?\n",
    "✅ Callback = \"something that runs automatically during training\". A callback is a tool in Keras that runs automatically during training to help monitor, stop, or save your model. Callbacks make your training smarter.\n",
    "\n",
    "* Think of callbacks like smart assistants that:\n",
    "1. Watch your model train\n",
    "2. Take actions at the end of each epoch (like saving, stopping, printing, logging)\n",
    "\n",
    "\n",
    "* Think of callbacks as helpers that Keras uses to monitor training and do things like:\n",
    "1. Stop early if it’s not improving\n",
    "2. Save the model\n",
    "3. Log progress\n",
    "\n",
    "They are like “custom instructions” that run at the end of each epoch during training.\n",
    "\n",
    "\n",
    "Common Types of Callbacks:\n",
    "\n",
    "Callback Name\n",
    "EarlyStopping---->Stops training if the model stops improving\n",
    "\n",
    "ModelCheckpoint---->Saves the best version of your model automatically\n",
    "\n",
    "TensorBoard---->Lets you see graphs, logs, and training metrics in your browser\n",
    "\n",
    "ReduceLROnPlateau---->Lowers learning rate if model stops improving\n",
    "____________________________________________________________________________________________________________________________\n",
    "\n",
    "🛑 What is EarlyStopping?\n",
    "EarlyStopping is a callback that stops training early if the model’s performance stops getting better (like if validation loss doesn't improve). It helps: Save time and Prevent overfitting. EarlyStopping prevents wasting time training when the model has already done its best.\n",
    "\n",
    "\n",
    "\n",
    "➤ Purpose:Stops training automatically when the model stops improving.\n",
    "\n",
    "✅ Why use it?\n",
    "1. To prevent overfitting (where your model learns the training data too well and does poorly on new data).\n",
    "2. To save time — no need to train extra epochs when the model isn’t getting better!\n",
    "\n",
    "____________________________________________________________________________________________________________________________\n",
    "\n",
    "What is TensorBoard?\n",
    "TensorBoard is a visual tool that helps you understand and debug your machine learning models.TensorBoard shows graphs, charts, and metrics (like accuracy, loss, etc.) while your model is training — in your web browser.It’s like a live report card for your model. TensorBoard is a browser-based tool to visualize model training in TensorFlow/Keras.It helps with\tDebugging, monitoring, and improving model performance.It is common with callbacks=[TensorBoard(...)] in model.fit()\n",
    "\n",
    "\n",
    "\n",
    "What Can TensorBoard Show You?\n",
    "\n",
    "Here’s what you can visualize with TensorBoard:\n",
    "Feature: \n",
    "\n",
    "Scalars---->Loss, accuracy, learning rate over time\n",
    "\n",
    "Graphs---->Your model’s architecture (layers, connections)\n",
    "\n",
    "Histograms---->Distributions of weights and biases\n",
    "\n",
    "Images & Text---->If you’re working with images or NLP, you can see them too\n",
    "\n",
    "Projector---->View word embeddings in 3D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a461baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],)     ## This , (blank) means it is a single dimension and it has 12 inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43233cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vishal Vishwakarma\\Downloads\\ANN CLASSIFICATION\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Build Our ANN Model\n",
    "model= Sequential([\n",
    "    Dense(64,activation='relu',input_shape= (X_train.shape[1],)), ## HL 1 connected with input layer. ##Here first I need to give my input and my hidden layer 1 \n",
    "    Dense(32,activation='relu'),    ## HL 2\n",
    "    Dense(1,activation='sigmoid')     ## Output layer\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4951d",
   "metadata": {},
   "source": [
    "* What is Dense(...)?\n",
    "A Dense layer is a layer where every neuron is connected to every input or neuron from the previous layer. It's called fully connected.\n",
    "\n",
    "* Dense(64, activation='relu', input_shape=(X_train.shape[1],))   ----->means\n",
    "What Each Part Means:\n",
    "\n",
    "1. Dense(64, ...) ----> This creates a Dense layer with 64 neurons.\n",
    "\n",
    "2. activation='relu' ----> Each of those 64 neurons will use the ReLU activation function.\n",
    "\n",
    "3. input_shape=(X_train.shape[1],) ----> This tells Keras the shape of the input data.\n",
    "\n",
    "_____________________________________________________________________________________________\n",
    "* 64 — Number of Neurons: This means: The first hidden layer will have 64 neurons. Each of them will receive input from every input feature.\n",
    "\n",
    "* 2. activation='relu' — Activation Function\n",
    "* ReLU stands for Rectified Linear Unit\n",
    "\n",
    "* It changes each number like this:\n",
    "​✅ ReLU makes the model better at learning complex patterns, and helps prevent some training problems.\n",
    "\n",
    "_______________________________________________________________________________________________\n",
    "\n",
    "✅ 3. input_shape=(X_train.shape[1],)\n",
    "* X_train.shape[1] means: the number of input features (columns) in your training data\n",
    "\n",
    "* Example: if your data has 10 input features, this becomes: input_shape=(10,)\n",
    "⚠️ input_shape is only needed in the first layer to tell the model the shape of the input data.\n",
    "\n",
    "Summary Table:\n",
    "Code Piece:\n",
    "1. Dense(64) -----> 64 neurons (nodes) in this layer.\n",
    "\n",
    "2. activation='relu' ----> Use ReLU function to activate the neurons.\n",
    "\n",
    "3. input_shape=(X_train.shape[1],) ----> Input has the same number of features as your training data.\n",
    "\n",
    "________________________________________________________________________________________________\n",
    "\n",
    "👉 What does the 1 mean in X_train.shape[1]?\n",
    "      In Python and NumPy, shape tells you the dimensions of an array or dataset.\n",
    " Example: Suppose your X_train looks like this:\n",
    " It might have:\n",
    "* 8000 rows (samples)\n",
    "* 3 columns (features),   Then X_train.shape → (8000, 3)\n",
    "_______________________________________________________________________________________________\n",
    "✅ Now:\n",
    "X_train.shape[0] → 8000 → number of rows (samples)\n",
    "\n",
    "X_train.shape[1] → 3 → number of features (columns)\n",
    "\n",
    "📌 So in input_shape=(X_train.shape[1],):\n",
    "* You're telling Keras: “Each input has X_train.shape[1] features.”\n",
    "\n",
    "* The comma in (X_train.shape[1],) makes it a tuple — required by Keras.\n",
    "_____________________________________________________________________________________________________\n",
    "Summary:\n",
    "Code:\n",
    "X_train.shape\t----> Tuple with (number of samples, number of features)\n",
    "X_train.shape[1]\t----> Number of features (columns)\n",
    "input_shape=(X_train.shape[1],)\t----> Tell Keras the shape of each input row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "50583ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5c2b8",
   "metadata": {},
   "source": [
    "Now in order to do the forward and the backward propogation, we need to compile this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32539570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LossFunctionWrapper(<function binary_crossentropy at 0x0000023E82675440>, kwargs={'from_logits': False, 'label_smoothing': 0.0, 'axis': -1})>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "opt=tensorflow.keras.optimizers.Adam(learning_rate=0.1)\n",
    "loss=tensorflow.keras.losses.BinaryCrossentropy()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "278c926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a3d41",
   "metadata": {},
   "source": [
    "Steps Explaination:\n",
    "* import tensorflow ---->👉 This loads the TensorFlow library so you can use its functions for deep   learning.\n",
    "\n",
    "* (Define the Optimizer) \n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.1) ----> 👉 You're using the Adam optimizer, which helps the model learn by updating weights during training.\n",
    "📌 learning_rate=0.1: Controls how big the steps are when updating weights. (0.1 is quite high—usually 0.001 is safer.)\n",
    "\n",
    "* (Define the Loss Function)\n",
    "\n",
    "loss = tensorflow.keras.losses.BinaryCrossentropy() ---->\n",
    "👉 This defines how we measure the model's error for binary classification (like spam/not spam, yes/no).\n",
    "📌 The model tries to minimize this loss during training.\n",
    "\n",
    "*  (Compile the Model)\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy']) ---->\n",
    "👉 This gets your model ready to train by setting:\n",
    "1. optimizer=opt: Uses the Adam optimizer.\n",
    "\n",
    "2. loss=\"binary_crossentropy\": Tells the model how to measure error.\n",
    "\n",
    "3. metrics=['accuracy']: Tracks accuracy while training (how many predictions are correct).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the Tensorboard\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "log_dir=\"logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa764a",
   "metadata": {},
   "source": [
    "✅ Step-by-Step Explanation\n",
    "🔸 Step 1: Import Callbacks:\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard  --->👉 These are tools that help control or monitor training:\n",
    "* EarlyStopping stops training if the model stops improving.\n",
    "\n",
    "* TensorBoard is for visualizing training progress (like loss, accuracy graphs).\n",
    "\n",
    "\n",
    "🔸 Step 2: Create a Log Directory:\n",
    "\n",
    "log_dir = \"logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") ----> 👉 Creates a folder name (like logs/fit20250702-1945) where logs will be saved.\n",
    "📌 datetime.now() adds the current date and time to avoid overwriting old logs.\n",
    "\n",
    "\n",
    "🔸 What is log in log_dir?\n",
    "In this line:\n",
    "\n",
    "log_dir = \"logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") ----> log is short for log files. These are saved records of what happens during model training—like: Loss, Accuracy, Learning rate, Histograms of weights, etc.\n",
    "\n",
    "🔸 What is \"logs/fit\"?\n",
    "\n",
    "* \"logs\" is the main folder. \n",
    "\n",
    "* \"fit\" is a subfolder (you can name it anything).\n",
    "\n",
    "* (+) datetime... adds the current date & time to keep each training log unique.\n",
    "\n",
    "\n",
    "📂 So the final folder path looks like:\n",
    "\n",
    "logs/fit20250702-1950\n",
    "\n",
    "\n",
    "🔸 Why do we need it? --> TensorBoard reads these logs to show nice visual graphs of how your model is learning.\n",
    "\n",
    "\n",
    "\n",
    "Step 3: Set Up TensorBoard Callback:\n",
    "\n",
    "tensorflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1) ----> 👉 This tells TensorBoard to:\n",
    "\n",
    "* Save training logs to log_dir.\n",
    "\n",
    "* Track histograms of weights every epoch (with histogram_freq=1).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c3781e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Early Stopping\n",
    "early_stopping_callback= EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549836d",
   "metadata": {},
   "source": [
    "Step-by-Step Explanation:\n",
    "1. EarlyStopping\n",
    "👉 A callback that automatically stops training when the model stops improving.\n",
    "\n",
    "2. monitor='val_loss'\n",
    "👉 It watches the validation loss after each epoch.\n",
    "\n",
    "3. patience=5\n",
    "👉 If validation loss doesn’t improve for 5 epochs, it stops training.\n",
    "\n",
    "4. restore_best_weights=True\n",
    "👉 After stopping, it restores the best model weights (from the epoch with the lowest val_loss).\n",
    "\n",
    "🧠 Summary:\n",
    "Stops training early if your model stops getting better, and keeps the best version of the model.\n",
    "\n",
    "________________________________________________________________________________________________________\n",
    "✅ What is Early Stopping (in terms of loss and epochs)?\n",
    "EarlyStopping is a technique to automatically stop training your model when it stops improving—so you don’t overfit and waste time. EarlyStopping stops training when the validation loss doesn't get better for a while. This prevents overfitting and saves time.\n",
    "\n",
    "\n",
    "🔍 How does it work (step-by-step)?\n",
    "* After each epoch, it checks the validation loss (not training loss).\n",
    "\n",
    "* If the validation loss decreases → it saves the model and continues training.\n",
    "\n",
    "* If the validation loss increases or stays the same for a few epochs, it waits (this is called patience).\n",
    "\n",
    "* If no improvement happens for those many epochs → it stops training early.\n",
    "________________________________________________________________________________________________________\n",
    "\n",
    "What is Validation Loss?\n",
    "Validation loss is the error your model makes on data it has never seen before — called the validation set.\n",
    "\n",
    "🔍 In simple terms:\n",
    "During training, you split your dataset like this:\n",
    "\n",
    "* Training data → used to train the model (update weights).\n",
    "\n",
    "* Validation data → used to check how well the model is generalizing.\n",
    "\n",
    "\n",
    "📊 Loss types:\n",
    "Loss Type:\n",
    "Training Loss\t---> Error on the training data.\n",
    "Validation Loss\t---> Error on the validation data.\n",
    "\n",
    "\n",
    "🧠 Why is Validation Loss important?\n",
    "If training loss ↓ but validation loss ↑, your model is overfitting — it’s memorizing instead of learning. We want both training loss and validation loss to go down.\n",
    "\n",
    "📉 Example:\n",
    "Epoch\tTraining Loss\tValidation Loss\n",
    "1\t        0.60\t          0.58\n",
    "2\t        0.50\t          0.48\n",
    "3\t        0.40\t          0.55 ❌\n",
    "\n",
    "At Epoch 3, validation loss increases → model is overfitting → early stopping can help!\n",
    "______________________________________________________________________________________________________\n",
    "\n",
    "✅ What is Training Loss?\n",
    "Training loss is the error (or difference) between the model's predictions and the actual labels on the training data.\n",
    "\n",
    "\n",
    "🔍 In simple words:\n",
    "It tells you how well your model is learning from the data you gave it during training.\n",
    "\n",
    "\n",
    "📊 Example:\n",
    "If you're training a model to detect cats vs. dogs:\n",
    "\n",
    "* Your model predicts dog for an image of a cat → ❌ wrong → some loss is added.\n",
    "\n",
    "* The model gets better over time → makes fewer mistakes → training loss decreases.\n",
    "\n",
    "\n",
    "📉 Goal: We want the training loss to go down over epochs. That means the model is learning and improving on the training data.\n",
    "\n",
    "\n",
    "🤔 But be careful: A very low training loss does not always mean a good model. It might be memorizing the training data → leading to overfitting. That’s why we also check validation loss.\n",
    "\n",
    "\n",
    "🧠 Summary:\n",
    "\n",
    "Term:\t                What it Measures:\t                                        Data Used:\n",
    "Training Loss\t        Model error on data it trained on\t                     Training data\n",
    "Validation Loss\t        Model error on unseen data (checks generalization)\t     Validation data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f072208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vishal Vishwakarma\\Downloads\\ANN CLASSIFICATION\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.7869 - loss: 0.5378 - val_accuracy: 0.8035 - val_loss: 0.4848\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7893 - loss: 0.4621 - val_accuracy: 0.8035 - val_loss: 0.3979\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7876 - loss: 0.4698 - val_accuracy: 0.8035 - val_loss: 0.4296\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7905 - loss: 0.4360 - val_accuracy: 0.8035 - val_loss: 0.4182\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7964 - loss: 0.4207 - val_accuracy: 0.8035 - val_loss: 0.4086\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7925 - loss: 0.4272 - val_accuracy: 0.8035 - val_loss: 0.4061\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.8001 - loss: 0.4008 - val_accuracy: 0.8035 - val_loss: 0.3937\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.8049 - loss: 0.4106 - val_accuracy: 0.7940 - val_loss: 0.4864\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7880 - loss: 0.4323 - val_accuracy: 0.8035 - val_loss: 0.3963\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7949 - loss: 0.3957 - val_accuracy: 0.8515 - val_loss: 0.4421\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.8261 - loss: 0.4154 - val_accuracy: 0.8035 - val_loss: 0.4126\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.8004 - loss: 0.4226 - val_accuracy: 0.8435 - val_loss: 0.3815\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.8319 - loss: 0.4146 - val_accuracy: 0.8030 - val_loss: 0.4157\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7892 - loss: 0.4359 - val_accuracy: 0.8025 - val_loss: 0.3938\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.8027 - loss: 0.4068 - val_accuracy: 0.8035 - val_loss: 0.4386\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8254 - loss: 0.3995 - val_accuracy: 0.8270 - val_loss: 0.4123\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.8364 - loss: 0.3868 - val_accuracy: 0.8405 - val_loss: 0.4215\n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "history=model.fit(\n",
    "    X_train,y_train,validation_data=(X_test,y_test),epochs=100,\n",
    "    callbacks=[tensorflow_callback,early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3b3dda8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64417678",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Tensorboard Extension\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ee59de93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 4772), started 0:07:08 ago. (Use '!kill 4772' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3a52d2f17b0a5ee2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3a52d2f17b0a5ee2\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit20250703-003054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c905b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1ef68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
